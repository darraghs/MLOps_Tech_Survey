@inproceedings{aguilarEaseMLLifecycle2021,
  title = {Ease.{{ML}}: {{A Lifecycle Management System}} for {{MLDev}} and {{MLOps}}},
  shorttitle = {Ease.{{ML}}},
  author = {Aguilar, Leonel and Dao, David and Gan, Shaoduo and Gurel, Nezihe Merve and Hollenstein, Nora and Jiang, Jiawei and Karlas, Bojan and Lemmin, Thomas and Li, Tian and Li, Yang and Rao, Susie and Rausch, Johannes and Renggli, Cedric and Rimanic, Luka and Weber, Maurice and Zhang, Shuai and Zhao, Zhikuan and Schawinski, Kevin and Wu, Wentao and Zhang, Ce},
  date = {2021-01-01},
  url = {https://www.microsoft.com/en-us/research/publication/ease-ml-a-lifecycle-management-system-for-mldev-and-mlops/},
  urldate = {2023-02-12},
  abstract = {We present Ease.ML, a lifecycle management system for machine learning (ML). Unlike many existing works, which focus on improving individual steps during the lifecycle of ML application development, Ease.ML focuses on managing and automating the entire lifecycle itself. We present user scenarios that have motivated the development of Ease.ML, the eight-step Ease.ML process that covers […]},
  eventtitle = {Conference on {{Innovative Data Systems Research}} ({{CIDR}} 2021)},
  langid = {american}
}

@misc{ashmoreAssuringMachineLearning2019,
  title = {Assuring the {{Machine Learning Lifecycle}}: {{Desiderata}}, {{Methods}}, and {{Challenges}}},
  shorttitle = {Assuring the {{Machine Learning Lifecycle}}},
  author = {Ashmore, Rob and Calinescu, Radu and Paterson, Colin},
  date = {2019-05-10},
  number = {arXiv:1905.04223},
  eprint = {1905.04223},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1905.04223},
  urldate = {2023-02-12},
  abstract = {Machine learning has evolved into an enabling technology for a wide range of highly successful applications. The potential for this success to continue and accelerate has placed machine learning (ML) at the top of research, economic and political agendas. Such unprecedented interest is fuelled by a vision of ML applicability extending to healthcare, transportation, defence and other domains of great societal importance. Achieving this vision requires the use of ML in safety-critical applications that demand levels of assurance beyond those needed for current ML applications. Our paper provides a comprehensive survey of the state-of-the-art in the assurance of ML, i.e. in the generation of evidence that ML is sufficiently safe for its intended use. The survey covers the methods capable of providing such evidence at different stages of the machine learning lifecycle, i.e. of the complex, iterative process that starts with the collection of the data used to train an ML component for a system, and ends with the deployment of that component within the system. The paper begins with a systematic presentation of the ML lifecycle and its stages. We then define assurance desiderata for each stage, review existing methods that contribute to achieving these desiderata, and identify open challenges that require further research.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,Statistics - Machine Learning}
}

@inproceedings{cardososilvaBenchmarkingMachineLearning2020,
  title = {Benchmarking {{Machine Learning Solutions}} in {{Production}}},
  booktitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  author = {Cardoso Silva, Lucas and Rezende Zagatti, Fernando and Silva Sette, Bruno and Nildaimon dos Santos Silva, Lucas and Lucrédio, Daniel and Furtado Silva, Diego and de Medeiros Caseli, Helena},
  options = {useprefix=true},
  date = {2020-12},
  pages = {626--633},
  doi = {10.1109/ICMLA51294.2020.00104},
  abstract = {Machine learning (ML) is becoming critical to many businesses. Keeping an ML solution online and responding is therefore a necessity, and is part of the MLOps (Machine Learning operationalization) movement. One aspect for this process is monitoring not only prediction quality, but also system resources. This is important to correctly provide the necessary infrastructure, either using a fully-managed cloud platform or a local solution. This is not a difficult task, as there are many tools available. However, it requires some planning and knowledge about what to monitor. Also, many ML professionals are not experts in system operations and may not have the skills to easily setup a monitoring and benchmarking environment. In the spirit of MLOps, this paper presents an approach, based on a simple API and set of tools, to monitor ML solutions. The approach was tested with 9 different solutions. The results indicate that the approach can deliver useful information to help in decision making, proper resource provision and operation of ML systems.},
  eventtitle = {2020 19th {{IEEE International Conference}} on {{Machine Learning}} and {{Applications}} ({{ICMLA}})},
  keywords = {Benchmark,Benchmark testing,Machine learning,Machine Learning,MLOps,Monitoring,Production,Systems operation,Task analysis,Tools},
  file = {/Users/dsherwin/Zotero/storage/7NFU7TFX/9356298.html}
}

@inproceedings{dasMachineLearningApplication2021,
  title = {Machine {{Learning}} Application Lifecycle Augmented with Explanation and Security},
  booktitle = {2021 {{IEEE}} 12th {{Annual Ubiquitous Computing}}, {{Electronics}} \& {{Mobile Communication Conference}} ({{UEMCON}})},
  author = {Das, Saikat and Shiva, Sajjan},
  date = {2021-12},
  pages = {0171--0177},
  doi = {10.1109/UEMCON53757.2021.9666619},
  abstract = {We have developed a Distributed Denial of Service (DDoS) intrusion detection framework that employs ML ensembles of both supervised and unsupervised classifiers that are complementary in reaching a corroborated classification decision. Our work has been limited to DDoS attack detection techniques. We propose to extend our framework to general ML system development, based on our review of current ML system development life cycles. We also propose to augment the general life cycle model to include security features to enable building security-in as the development progresses and bolt security-on as flaws are discovered after deployment. Most ML systems today operate in a black-box mode, providing users with only the predictions without associated reasoning as to how the predictions are brought about. There is heavy emphasis now to build mechanisms that help the user develop higher confidence in accepting the predictions of ML systems. Such explainability feature of ML model predictions is a must for critical systems. We also propose to augment our lifecycle model with explainability features. Thus, our ultimate goal is to develop a generic ML lifecycle process augmented with security and explainability features. Such an ML lifecycle process will be of immense use in ML systems development for all domains.},
  eventtitle = {2021 {{IEEE}} 12th {{Annual Ubiquitous Computing}}, {{Electronics}} \& {{Mobile Communication Conference}} ({{UEMCON}})},
  keywords = {Buildings,Denial-of-service attack,explanation augmented ML life cycle,Fasteners,Intrusion detection,Machine learning,Machine learning life cycle,MLOpS,Mobile communication,Predictive models,security augmented ML life cycle},
  file = {/Users/dsherwin/Zotero/storage/JWLXZ5TP/9666619.html}
}

@misc{gargContinuousIntegrationContinuous2022,
  title = {On {{Continuous Integration}} / {{Continuous Delivery}} for {{Automated Deployment}} of {{Machine Learning Models}} Using {{MLOps}}},
  author = {Garg, Satvik and Pundir, Pradyumn and Rathee, Geetanjali and Gupta, P. K. and Garg, Somya and Ahlawat, Saransh},
  date = {2022-02-07},
  number = {arXiv:2202.03541},
  eprint = {2202.03541},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.03541},
  url = {http://arxiv.org/abs/2202.03541},
  urldate = {2023-02-12},
  abstract = {Model deployment in machine learning has emerged as an intriguing field of research in recent years. It is comparable to the procedure defined for conventional software development. Continuous Integration and Continuous Delivery (CI/CD) have been shown to smooth down software advancement and speed up businesses when used in conjunction with development and operations (DevOps). Using CI/CD pipelines in an application that includes Machine Learning Operations (MLOps) components, on the other hand, has difficult difficulties, and pioneers in the area solve them by using unique tools, which is typically provided by cloud providers. This research provides a more in-depth look at the machine learning lifecycle and the key distinctions between DevOps and MLOps. In the MLOps approach, we discuss tools and approaches for executing the CI/CD pipeline of machine learning frameworks. Following that, we take a deep look into push and pull-based deployments in Github Operations (GitOps). Open exploration issues are also identified and added, which may guide future study.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@inproceedings{granlundMLOpsChallengesMultiOrganization2021,
  title = {{{MLOps Challenges}} in {{Multi-Organization Setup}}: {{Experiences}} from {{Two Real-World Cases}}},
  shorttitle = {{{MLOps Challenges}} in {{Multi-Organization Setup}}},
  booktitle = {2021 {{IEEE}}/{{ACM}} 1st {{Workshop}} on {{AI Engineering}} - {{Software Engineering}} for {{AI}} ({{WAIN}})},
  author = {Granlund, Tuomas and Kopponen, Aleksi and Stirbu, Vlad and Myllyaho, Lalli and Mikkonen, Tommi},
  date = {2021-05},
  pages = {82--88},
  doi = {10.1109/WAIN52551.2021.00019},
  abstract = {The emerging age of connected, digital world means that there are tons of data, distributed to various organizations and their databases. Since this data can be confidential in nature, it cannot always be openly shared in seek of artificial intelligence (AI) and machine learning (ML) solutions. Instead, we need integration mechanisms, analogous to integration patterns in information systems, to create multi-organization AI/ML systems. In this paper, we present two real-world cases. First, we study integration between two organizations in detail. Second, we address scaling of AI/ML to multi-organization context. The setup we assume is that of continuous deployment, often referred to DevOps in software development. When also ML components are deployed in a similar fashion, term MLOps is used. Towards the end of the paper, we list the main observations and draw some final conclusions. Finally, we propose some directions for future work.},
  eventtitle = {2021 {{IEEE}}/{{ACM}} 1st {{Workshop}} on {{AI Engineering}} - {{Software Engineering}} for {{AI}} ({{WAIN}})},
  keywords = {Artificial intelligence; AI,Data models,Distributed databases,information systems,integration,Learning (artificial intelligence),Machine learning,machine learning; ML,multi-organisation,Organizations,Pipelines,Software,software engineering for AI/ML},
  file = {/Users/dsherwin/Zotero/storage/JFXZRREP/9474388.html}
}

@unpublished{hewageMachineLearningOperations2022,
  title = {Machine {{Learning Operations}}: {{A Survey}} on {{MLOps Tool Support}}},
  shorttitle = {Machine {{Learning Operations}}},
  author = {Hewage, Nipuni and Meedeniya, Dulani},
  date = {2022},
  eprint = {2202.10169},
  eprinttype = {arxiv},
  primaryclass = {cs},
  doi = {10.48550/arXiv.2202.10169},
  url = {http://arxiv.org/abs/2202.10169},
  urldate = {2023-02-12},
  abstract = {Machine Learning (ML) has become a fast-growing, trending approach in solution development in practice. Deep Learning (DL) which is a subset of ML, learns using deep neural networks to simulate the human brain. It trains machines to learn techniques and processes individually using computer algorithms, which is also considered to be a role of Artificial Intelligence (AI). In this paper, we study current technical issues related to software development and delivery in organizations that work on ML projects. Therefore, the importance of the Machine Learning Operations (MLOps) concept, which can deliver appropriate solutions for such concerns, is discussed. We investigate commercially available MLOps tool support in software development. The comparison between MLOps tools analyzes the performance of each system and its use cases. Moreover, we examine the features and usability of MLOps tools to identify the most appropriate tool support for given scenarios. Finally, we recognize that there is a shortage in the availability of a fully functional MLOps platform on which processes can be automated by reducing human intervention.},
  archiveprefix = {arXiv},
  keywords = {A.1,Computer Science - Software Engineering,D.2.6,K.6.3}
}

@inproceedings{johnMLOpsFrameworkMaturity2021,
  title = {Towards {{MLOps}}: {{A Framework}} and {{Maturity Model}}},
  shorttitle = {Towards {{MLOps}}},
  booktitle = {2021 47th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  author = {John, Meenu Mary and Olsson, Helena Holmström and Bosch, Jan},
  date = {2021-09},
  pages = {1--8},
  doi = {10.1109/SEAA53835.2021.00050},
  abstract = {The adoption of continuous software engineering practices such as DevOps (Development and Operations) in business operations has contributed to significantly shorter software development and deployment cycles. Recently, the term MLOps (Machine Learning Operations) has gained increasing interest as a practice that brings together data scientists and operations teams. However, the adoption of MLOps in practice is still in its infancy and there are few common guidelines on how to effectively integrate it into existing software development practices. In this paper, we conduct a systematic literature review and a grey literature review to derive a framework that identifies the activities involved in the adoption of MLOps and the stages in which companies evolve as they become more mature and advanced. We validate this framework in three case companies and show how they have managed to adopt and integrate MLOps in their large-scale software development companies. The contribution of this paper is threefold. First, we review contemporary literature to provide an overview of the state-of-the-art in MLOps. Based on this review, we derive an MLOps framework that details the activities involved in the continuous development of machine learning models. Second, we present a maturity model in which we outline the different stages that companies go through in evolving their MLOps practices. Third, we validate our framework in three embedded systems case companies and map the companies to the stages in the maturity model.},
  eventtitle = {2021 47th {{Euromicro Conference}} on {{Software Engineering}} and {{Advanced Applications}} ({{SEAA}})},
  keywords = {Bibliographies,Companies,Embedded systems,Framework,GLR,Machine learning,Maturity Model,MLOps,SLR,Software,Software engineering,Systematics,Validation Study},
  file = {/Users/dsherwin/Zotero/storage/ZICBX8QT/9582569.html}
}

@misc{kreuzbergerMachineLearningOperations2022,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}}},
  shorttitle = {Machine {{Learning Operations}} ({{MLOps}})},
  author = {Kreuzberger, Dominik and Kühl, Niklas and Hirschl, Sebastian},
  date = {2022-05-14},
  number = {arXiv:2205.02302},
  eprint = {2205.02302},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2205.02302},
  url = {http://arxiv.org/abs/2205.02302},
  urldate = {2023-02-12},
  abstract = {The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we provide an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we furnish a definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@misc{makinenWhoNeedsMLOps2021,
  title = {Who {{Needs MLOps}}: {{What Data Scientists Seek}} to {{Accomplish}} and {{How Can MLOps Help}}?},
  shorttitle = {Who {{Needs MLOps}}},
  author = {Mäkinen, Sasu and Skogström, Henrik and Laaksonen, Eero and Mikkonen, Tommi},
  date = {2021-03-16},
  number = {arXiv:2103.08942},
  eprint = {2103.08942},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2103.08942},
  urldate = {2023-02-12},
  abstract = {Following continuous software engineering practices, there has been an increasing interest in rapid deployment of machine learning (ML) features, called MLOps. In this paper, we study the importance of MLOps in the context of data scientists' daily activities, based on a survey where we collected responses from 331 professionals from 63 different countries in ML domain, indicating on what they were working on in the last three months. Based on the results, up to 40\% respondents say that they work with both models and infrastructure; the majority of the work revolves around relational and time series data; and the largest categories of problems to be solved are predictive analysis, time series data, and computer vision. The biggest perceived problems revolve around data, although there is some awareness of problems related to deploying models to production and related procedures. To hypothesise, we believe that organisations represented in the survey can be divided to three categories -- (i) figuring out how to best use data; (ii) focusing on building the first models and getting them to production; and (iii) managing several models, their versions and training datasets, as well as retraining and frequent deployment of retrained models. In the results, the majority of respondents are in category (i) or (ii), focusing on data and models; however the benefits of MLOps only emerge in category (iii) when there is a need for frequent retraining and redeployment. Hence, setting up an MLOps pipeline is a natural step to take, when an organization takes the step from ML as a proof-of-concept to ML as a part of nominal activities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Software Engineering}
}

@inproceedings{mboweniSystematicReviewMachine2022,
  title = {A {{Systematic Review}} of {{Machine Learning DevOps}}},
  booktitle = {2022 {{International Conference}} on {{Electrical}}, {{Computer}} and {{Energy Technologies}} ({{ICECET}})},
  author = {Mboweni, Tsakani and Masombuka, Themba and Dongmo, Cyrille},
  date = {2022-07},
  pages = {1--6},
  doi = {10.1109/ICECET55527.2022.9872968},
  abstract = {DevOps and Machine Learning (ML) on their own are insufficient in certain organisational context. To achieve the desired results, industries are now combining the benefits of DevOps automation and machine learning capabilities. This synergy is known as Machine Learning DevOps (ML-DevOps). However, there is currently no shared vision, strategy, or guidance across industry enterprises on how to use ML-DevOps for application development. While still in its infancy, ML-DevOps has showed some prospects to become a dynamic approach for developing and delivering secure, robust, and scalable applications. This article describes a systematic review of peer-reviewed conference papers and journal articles on ML-DevOps from 2015 to 2022 to ascertain the state-of-the-art and then identify any gaps in the current literature. Using empirical analysis, we systematically examined more than 60 studies that primarily deal with ML-DevOps (commonly referred to as MLOps). We combined meta analysis, document analysis and triangulation to map how ML-DevOps is currently understood and how it compares and differs from related approaches such as DevOps. The articles used were accessed via credible scholarly databases. The results of our search strategy retrieved articles that primarily discuss the topics of ML and DevOps synergy. The review of the existing literature shows a paucity of studies that strictly investigate ML-DevOps/MLOps. In most cases, the focus of these studies is on clarifying the meaning of MLOps. Our study discovered that although there are common elements in the definitions of MLOps, there remains a lack of standardisation on how it is defined, which sometimes cause some misconceptions and ambiguity. Finally, although there is significant literature written on MLOps, the review did not find evidence that there is a common understanding amongst scholars and experts on how MLOps should be implemented and institutionalized across industry to create a common vision.},
  eventtitle = {2022 {{International Conference}} on {{Electrical}}, {{Computer}} and {{Energy Technologies}} ({{ICECET}})},
  keywords = {Automation,Databases,DevOps,Industries,Machine learning,Machine Learning,ML-DevOps,MLOps,Search problems,Systematics,Text analysis},
  file = {/Users/dsherwin/Zotero/storage/DQT4U8T5/9872968.html}
}

@misc{muralidharUsingAntiPatternsAvoid2021,
  title = {Using {{AntiPatterns}} to Avoid {{MLOps Mistakes}}},
  author = {Muralidhar, Nikhil and Muthiah, Sathappah and Butler, Patrick and Jain, Manish and Yu, Yu and Burne, Katy and Li, Weipeng and Jones, David and Arunachalam, Prakash and McCormick, Hays 'Skip' and Ramakrishnan, Naren},
  date = {2021-06-30},
  number = {arXiv:2107.00079},
  eprint = {2107.00079},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.00079},
  url = {http://arxiv.org/abs/2107.00079},
  urldate = {2023-02-12},
  abstract = {We describe lessons learned from developing and deploying machine learning models at scale across the enterprise in a range of financial analytics applications. These lessons are presented in the form of antipatterns. Just as design patterns codify best software engineering practices, antipatterns provide a vocabulary to describe defective practices and methodologies. Here we catalog and document numerous antipatterns in financial ML operations (MLOps). Some antipatterns are due to technical errors, while others are due to not having sufficient knowledge of the surrounding context in which ML results are used. By providing a common vocabulary to discuss these situations, our intent is that antipatterns will support better documentation of issues, rapid communication between stakeholders, and faster resolution of problems. In addition to cataloging antipatterns, we describe solutions, best practices, and future directions toward MLOps maturity.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@inproceedings{ranawanaAgileSoftwareDevelopment2021,
  title = {An {{Agile Software Development Life Cycle Model}} for {{Machine Learning Application Development}}},
  booktitle = {2021 5th {{SLAAI International Conference}} on {{Artificial Intelligence}} ({{SLAAI-ICAI}})},
  author = {Ranawana, Romesh and Karunananda, Asoka S.},
  date = {2021-12},
  pages = {1--6},
  doi = {10.1109/SLAAI-ICAI54477.2021.9664736},
  abstract = {Software development teams are often hampered when aligning machine learning production with standard software development processes. Iterative experimentation is needed to address the inherent complexities of data collection and preparation, model entanglement, and the technical debt of machine learning. The complexity of this process is compounded due to dependencies on the production environment and real- time data. We propose a unified framework which facilitates the planning, development, and deployment of a machine learning application through parallel processes for software and machine learning engineering. This allows for the risk of both the project and machine learning development to be significantly reduced through continuous integration, evaluation, and production. The framework, named MLASDLC, unifies concepts from standard software development life cycle methodologies (SDLC), development operations (DevOps) and machine learning operations (MLOps) to present a framework for the development of machine learning applications.},
  eventtitle = {2021 5th {{SLAAI International Conference}} on {{Artificial Intelligence}} ({{SLAAI-ICAI}})},
  keywords = {agile,Agile software development,Complexity theory,Data collection,Data models,data-centric,DevOps,experimentation,Machine learning,MLOps,Production,SDLC,Software,software development life cycle},
  file = {/Users/dsherwin/Zotero/storage/CCTSBDEU/9664736.html}
}

@misc{renggliDataQualityDrivenView2021,
  title = {A {{Data Quality-Driven View}} of {{MLOps}}},
  author = {Renggli, Cedric and Rimanic, Luka and Gürel, Nezihe Merve and Karlaš, Bojan and Wu, Wentao and Zhang, Ce},
  date = {2021-02-15},
  number = {arXiv:2102.07750},
  eprint = {2102.07750},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2102.07750},
  url = {http://arxiv.org/abs/2102.07750},
  urldate = {2023-02-12},
  abstract = {Developing machine learning models can be seen as a process similar to the one established for traditional software development. A key difference between the two lies in the strong dependency between the quality of a machine learning model and the quality of the data used to train or perform evaluations. In this work, we demonstrate how different aspects of data quality propagate through various stages of machine learning development. By performing a joint analysis of the impact of well-known data quality dimensions and the downstream machine learning process, we show that different components of a typical MLOps pipeline can be efficiently designed, providing both a technical and theoretical perspective.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning}
}

@article{rufDemystifyingMLOpsPresenting2021,
  title = {Demystifying {{MLOps}} and {{Presenting}} a {{Recipe}} for the {{Selection}} of {{Open-Source Tools}}},
  author = {Ruf, Philipp and Madan, Manav and Reich, Christoph and Ould-Abdeslam, Djaffar},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {19},
  pages = {8861},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app11198861},
  url = {https://www.mdpi.com/2076-3417/11/19/8861},
  urldate = {2023-02-12},
  abstract = {Nowadays, machine learning projects have become more and more relevant to various real-world use cases. The success of complex Neural Network models depends upon many factors, as the requirement for structured and machine learning-centric project development management arises. Due to the multitude of tools available for different operational phases, responsibilities and requirements become more and more unclear. In this work, Machine Learning Operations (MLOps) technologies and tools for every part of the overall project pipeline, as well as involved roles, are examined and clearly defined. With the focus on the inter-connectivity of specific tools and comparison by well-selected requirements of MLOps, model performance, input data, and system quality metrics are briefly discussed. By identifying aspects of machine learning, which can be reused from project to project, open-source tools which help in specific parts of the pipeline, and possible combinations, an overview of support in MLOps is given. Deep learning has revolutionized the field of Image processing, and building an automated machine learning workflow for object detection is of great interest for many organizations. For this, a simple MLOps workflow for object detection with images is portrayed.},
  issue = {19},
  langid = {english},
  keywords = {MlOps,quality metrics,tool comparison,workflow automation}
}

@article{sculleyHiddenTechnicalDebt2015,
  title = {Hidden {{Technical Debt}} in {{Machine Learning Systems}}},
  author = {Sculley, D and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Dennison, Dan},
  date = {2015-01-01},
  journaltitle = {NIPS},
  shortjournal = {NIPS},
  pages = {2494--2502},
  abstract = {Machine learning offers a fantastically powerful toolkit for building useful com-plex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.}
}

@misc{shankarOperationalizingMachineLearning2022,
  title = {Operationalizing {{Machine Learning}}: {{An Interview Study}}},
  shorttitle = {Operationalizing {{Machine Learning}}},
  author = {Shankar, Shreya and Garcia, Rolando and Hellerstein, Joseph M. and Parameswaran, Aditya G.},
  date = {2022-09-16},
  number = {arXiv:2209.09125},
  eprint = {2209.09125},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2209.09125},
  url = {http://arxiv.org/abs/2209.09125},
  urldate = {2023-02-12},
  abstract = {Organizations rely on machine learning engineers (MLEs) to operationalize ML, i.e., deploy and maintain ML pipelines in production. The process of operationalizing ML, or MLOps, consists of a continual loop of (i) data collection and labeling, (ii) experimentation to improve ML performance, (iii) evaluation throughout a multi-staged deployment process, and (iv) monitoring of performance drops in production. When considered together, these responsibilities seem staggering -- how does anyone do MLOps, what are the unaddressed challenges, and what are the implications for tool builders? We conducted semi-structured ethnographic interviews with 18 MLEs working across many applications, including chatbots, autonomous vehicles, and finance. Our interviews expose three variables that govern success for a production ML deployment: Velocity, Validation, and Versioning. We summarize common practices for successful ML experimentation, deployment, and sustaining production performance. Finally, we discuss interviewees' pain points and anti-patterns, with implications for tool design.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Computer Science - Software Engineering}
}

@misc{symeonidisMLOpsDefinitionsTools2022,
  title = {{{MLOps}} -- {{Definitions}}, {{Tools}} and {{Challenges}}},
  author = {Symeonidis, G. and Nerantzis, E. and Kazakis, A. and Papakostas, G. A.},
  date = {2022-01-01},
  number = {arXiv:2201.00162},
  eprint = {2201.00162},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2201.00162},
  url = {http://arxiv.org/abs/2201.00162},
  urldate = {2023-02-12},
  abstract = {This paper is an overview of the Machine Learning Operations (MLOps) area. Our aim is to define the operation and the components of such systems by highlighting the current problems and trends. In this context, we present the different tools and their usefulness in order to provide the corresponding guidelines. Moreover, the connection between MLOps and AutoML (Automated Machine Learning) is identified and how this combination could work is proposed.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Software Engineering,I.2}
}

@inproceedings{tamburriSustainableMLOpsTrends2020,
  title = {Sustainable {{MLOps}}: {{Trends}} and {{Challenges}}},
  shorttitle = {Sustainable {{MLOps}}},
  booktitle = {2020 22nd {{International Symposium}} on {{Symbolic}} and {{Numeric Algorithms}} for {{Scientific Computing}} ({{SYNASC}})},
  author = {Tamburri, Damian A.},
  date = {2020-09},
  pages = {17--23},
  doi = {10.1109/SYNASC51798.2020.00015},
  abstract = {Even simply through a GoogleTrends search it becomes clear that Machine-Learning Operations-or MLOps, for short-are climbing in interest from both a scientific and practical perspective. On the one hand, software components and middleware are proliferating to support all manners of MLOps, from AutoML (i.e., software which enables developers with limited machine-learning expertise to train high-quality models specific to their domain or data) to feature-specific ML engineering, e.g., Explainability and Interpretability. On the other hand, the more these platforms penetrate the day-to-day activities of software operations, the more the risk for AI Software becoming unsustainable from a social, technical, or organisational perspective. This paper offers a concise definition of MLOps and AI Software Sustainability and outlines key challenges in its pursuit.},
  eventtitle = {2020 22nd {{International Symposium}} on {{Symbolic}} and {{Numeric Algorithms}} for {{Scientific Computing}} ({{SYNASC}})},
  keywords = {DataOps,Decision making,Machine learning,Machine-Learning Operations,Market research,Middleware,MLOps,Scientific computing,Software Sustainability,Software systems,Sustainable development},
  file = {/Users/dsherwin/Zotero/storage/LXK5Z3W6/stamp.html}
}

@inproceedings{zhouMLOpsCaseStudy2020,
  title = {Towards {{MLOps}}: {{A Case Study}} of {{ML Pipeline Platform}}},
  shorttitle = {Towards {{MLOps}}},
  booktitle = {2020 {{International Conference}} on {{Artificial Intelligence}} and {{Computer Engineering}} ({{ICAICE}})},
  author = {Zhou, Yue and Yu, Yue and Ding, Bo},
  date = {2020-10},
  pages = {494--500},
  doi = {10.1109/ICAICE51518.2020.00102},
  abstract = {The development and deployment of machine learning (ML) applications differ significantly from traditional applications in many ways, which have led to an increasing need for efficient and reliable production of ML applications and supported infrastructures. Though platforms such as TensorFlow Extended (TFX), ModelOps, and Kubeflow have provided end-to-end lifecycle management for ML applications by orchestrating its phases into multistep ML pipelines, their performance is still uncertain. To address this, we built a functional ML platform with DevOps capability from existing continuous integration (CI) or continuous delivery (CD) tools and Kubeflow, constructed and ran ML pipelines to train models with different layers and hyperparameters while time and computing resources consumed were recorded. On this basis, we analyzed the time and resource consumption of each step in the ML pipeline, explored the consumption concerning the ML platform and computational models, and proposed potential performance bottlenecks such as GPU utilization. Our work provides a valuable reference for ML pipeline platform construction in practice.},
  eventtitle = {2020 {{International Conference}} on {{Artificial Intelligence}} and {{Computer Engineering}} ({{ICAICE}})},
  keywords = {Computational modeling,continuous training,Data models,DevOps,end-to-end platform,Graphics processing units,machine learning,MLOps,Pipelines,Task analysis,Tools,Training},
  file = {/Users/dsherwin/Zotero/storage/N2SW2R3L/9361315.html}
}
